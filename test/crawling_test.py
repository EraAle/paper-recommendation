from crawler import *

print("--- arxiv 호출해서 가져오기 테스트 ---")
# 케이스 1: 기본 (단일 키워드)
# keyword_list1 = ["attention"]
# field_list1 = ["title"]
# operator_list1 = ["AND"]
# query = make_query_arxiv(keyword_list1, operator_list1, field_list1)
# print(query)
# document = crawling_basic(query, num=125)
# document_print(document)

# document_filering = main_crawling(query, num=125, date=[2023, 2023])
# document_print(document_filering)

# keyword_list2 = ["robotics", "computer vision", "AI"]
# field_list2 = ["all"]
# operator_list2 = ["AND", "OR"]
# query = make_query_arxiv(keyword_list2, operator_list2, field_list2)
# print(query)
# document = crawling_basic(query, num=125)
# document_print(document)

# keyword_list3 = ["transformer", "google"]
# field_list3 = ["title", "abstract"]
# operator_list3 = ["AND"]
# query = make_query_arxiv(keyword_list3, operator_list3, field_list3)
# print(query)
# document_filering = main_crawling(query, num=125)
# document_print(document_filering)

# keyword_list4 = []
# field_list4 = []
# operator_list4 = []
# query = make_query_arxiv(keyword_list4, operator_list4, field_list4)
# print(query)
# document_filering = main_crawling(query, num=125)
# document_print(document_filering)

